{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1612973045711,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "ylmXqkVxrj1j"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21574,
     "status": "ok",
     "timestamp": 1612973067111,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "1AMVu46hovJr",
    "outputId": "0e2d1809-fcc9-479e-f9c8-572cd2549bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: deepposekit in c:\\users\\advait\\anaconda3\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: pyrealsense2 in c:\\users\\advait\\anaconda3\\lib\\site-packages (2.41.0.2666)\n",
      "Requirement already satisfied: h5py in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (5.4.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (4.5.1.48)\n",
      "Requirement already satisfied: numpy in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (1.19.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (1.1.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (3.3.2)\n",
      "Requirement already satisfied: imgaug>=0.2.9 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from deepposekit) (0.4.0)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (0.15.0)\n",
      "Requirement already satisfied: six in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (1.15.0)\n",
      "Requirement already satisfied: Shapely in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (1.7.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (8.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (1.5.2)\n",
      "Requirement already satisfied: imageio in c:\\users\\advait\\anaconda3\\lib\\site-packages (from imgaug>=0.2.9->deepposekit) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.2.9->deepposekit) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from scikit-image>=0.14.2->imgaug>=0.2.9->deepposekit) (2.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from matplotlib->deepposekit) (0.10.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from matplotlib->deepposekit) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from matplotlib->deepposekit) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from matplotlib->deepposekit) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from matplotlib->deepposekit) (1.3.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.2.9->deepposekit) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\advait\\anaconda3\\lib\\site-packages (from pandas->deepposekit) (2021.1)\n",
      "Using tensorflow v2.0.0\n",
      "E:\\Work\\github repos\\deepposekit_data_custom\\hand/ hand\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install -U deepposekit pyrealsense2\n",
    "\n",
    "# HOW TO USE THIS SCRIPT:\n",
    "\n",
    "# 1. Update the source\n",
    "# 2. Make sure annotator is uncommented\n",
    "# 3. Maybe change the text scaling\n",
    "\n",
    "from deepposekit import Annotator\n",
    "from deepposekit.io import VideoReader, DataGenerator, initialize_dataset, TrainingGenerator, BaseGenerator\n",
    "from deepposekit.io import ImageGenerator, VideoWriter\n",
    "from deepposekit.io.utils import merge_new_images\n",
    "from deepposekit.annotate import KMeansSampler\n",
    "from deepposekit.augment import FlipAxis\n",
    "from deepposekit.models import StackedDenseNet, DeepLabCut,StackedHourglass,LEAP\n",
    "from deepposekit.models import load_model\n",
    "\n",
    "from deepposekit.callbacks import Logger, ModelCheckpoint\n",
    "from scipy.signal import find_peaks\n",
    "#import pyrealsense2 as rs\n",
    "\n",
    "import tqdm\n",
    "import cv2\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "\n",
    "\n",
    "#source = 'chick-toy'\n",
    "#HOME = f\"{source}/\"\n",
    "\n",
    "from os.path import expanduser\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %tensorflow_version 1.x\n",
    "    import tensorflow as tf\n",
    "    print(\"Using tensorflow v\" + str(tf.__version__))\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "    data_path = '/content/drive/MyDrive/GitHub IU/bam/deepposekit_clone/deepposekit_data_custom/'\n",
    "    source = 'human'\n",
    "    HOME = data_path + f\"{source}/\"\n",
    "    print(HOME, source)\n",
    "    \n",
    "        \n",
    "except:\n",
    "    import tensorflow as tf\n",
    "    print(\"Using tensorflow v\" + str(tf.__version__))\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "    IN_COLAB = False\n",
    "    data_path = 'E:\\\\Work\\\\github repos\\\\deepposekit_data_custom\\\\'\n",
    "    source = 'hand'\n",
    "    HOME = data_path + f\"{source}/\"\n",
    "    print(HOME, source)\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 21566,
     "status": "ok",
     "timestamp": 1612973067112,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "ww-MxZIVqDU-",
    "outputId": "09190821-6845-48ed-aa19-72e64e0e7e37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Work\\\\github repos\\\\deepposekit_data_custom\\\\hand/hand_annotation_set.h5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME + f'{source}_annotation_set.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bdy91hM7ulwu"
   },
   "outputs": [],
   "source": [
    "resize_shape = (256, 256)\n",
    "\n",
    "cap = cv2.VideoCapture(HOME + f'{source}_raw.mp4')\n",
    " \n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "# out = cv2.VideoWriter(HOME + video_file_path + 'pose_human_test_resized.mp4',fourcc, 30, resize_shape)\n",
    "\n",
    "out = VideoWriter(HOME + f'{source}.mp4', resize_shape, 'mp4v', 30.0, color=True)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        b = cv2.resize(frame,resize_shape,fx=0,fy=0, interpolation = cv2.INTER_CUBIC)\n",
    "        out.write(b)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.close()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1612973077305,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "EgF0kAkHo4iA"
   },
   "outputs": [],
   "source": [
    "def annotate_dataset(overwrite=False):\n",
    "    print(\"[INFO] Preparing Data\")\n",
    "    # batch_size must be large else kmeans can't be performed\n",
    "    reader = VideoReader(HOME + f'{source}.mp4', batch_size=100, gray=True)\n",
    "\n",
    "    randomly_sampled_frames = []\n",
    "    for idx in tqdm.tqdm(range(len(reader)-1)):\n",
    "        batch = reader[idx]\n",
    "        random_sample = batch[np.random.choice(batch.shape[0], 10, replace=False)]\n",
    "        randomly_sampled_frames.append(random_sample)\n",
    "    reader.close()\n",
    "\n",
    "    randomly_sampled_frames = np.concatenate(randomly_sampled_frames)\n",
    "    kmeans = KMeansSampler(n_clusters=10, max_iter=100, n_init=20, batch_size=100, verbose=True)\n",
    "    kmeans.fit(randomly_sampled_frames)\n",
    "    kmeans_sampled_frames, kmeans_cluster_labels = kmeans.sample_data(randomly_sampled_frames, n_samples_per_label=50)\n",
    "\n",
    "    try:\n",
    "        initialize_dataset(\n",
    "            images=kmeans_sampled_frames,\n",
    "            datapath=HOME + f'{source}_annotation_set.h5',\n",
    "            skeleton=HOME + 'skeleton.csv',\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "    except OSError:\n",
    "        print(\"[INFO] Dataset Exists - Passing.\")\n",
    "\n",
    "    # THIS CANNOT BE DONE FROM WITHIN GOOGLE COLAB. USE PYCHARM or an IDE\n",
    "    Annotator(datapath = HOME + f'{source}_annotation_set.h5',\n",
    "                   dataset ='images',\n",
    "                   skeleton = HOME + 'skeleton.csv',\n",
    "                   shuffle_colors = False,\n",
    "                   text_scale = 0.2).run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1612973077530,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "bBquSTbtrA8v"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████████████████                     | 3/4 [00:00<00:00, 28.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/20 with method: k-means++\n",
      "Inertia for init 1/20: 207894923.795238\n",
      "Init 2/20 with method: k-means++\n",
      "Inertia for init 2/20: 219825053.740476\n",
      "Init 3/20 with method: k-means++\n",
      "Inertia for init 3/20: 159610670.600000\n",
      "Init 4/20 with method: k-means++\n",
      "Inertia for init 4/20: 202767483.203288\n",
      "Init 5/20 with method: k-means++\n",
      "Inertia for init 5/20: 164797227.800000\n",
      "Init 6/20 with method: k-means++\n",
      "Inertia for init 6/20: 181458656.657143\n",
      "Init 7/20 with method: k-means++\n",
      "Inertia for init 7/20: 159610670.600000\n",
      "Init 8/20 with method: k-means++\n",
      "Inertia for init 8/20: 155486544.266666\n",
      "Init 9/20 with method: k-means++\n",
      "Inertia for init 9/20: 178638881.933333\n",
      "Init 10/20 with method: k-means++\n",
      "Inertia for init 10/20: 181967097.800000\n",
      "Init 11/20 with method: k-means++\n",
      "Inertia for init 11/20: 207894923.795238\n",
      "Init 12/20 with method: k-means++\n",
      "Inertia for init 12/20: 174879088.133333\n",
      "Init 13/20 with method: k-means++\n",
      "Inertia for init 13/20: 180949854.835714\n",
      "Init 14/20 with method: k-means++\n",
      "Inertia for init 14/20: 159610670.600000\n",
      "Init 15/20 with method: k-means++\n",
      "Inertia for init 15/20: 201813192.240476\n",
      "Init 16/20 with method: k-means++\n",
      "Inertia for init 16/20: 181967097.800000\n",
      "Init 17/20 with method: k-means++\n",
      "Inertia for init 17/20: 175246619.457143\n",
      "Init 18/20 with method: k-means++\n",
      "Inertia for init 18/20: 154435029.266666\n",
      "Init 19/20 with method: k-means++\n",
      "Inertia for init 19/20: 181458656.657143\n",
      "Init 20/20 with method: k-means++\n",
      "Inertia for init 20/20: 200289898.133333\n",
      "Minibatch iteration 1/100: mean batch inertia: 8640232.405278, ewa inertia: 8640232.405278 \n",
      "Minibatch iteration 2/100: mean batch inertia: 7605433.061262, ewa inertia: 7605433.061262 \n",
      "Minibatch iteration 3/100: mean batch inertia: 6757824.195068, ewa inertia: 6757824.195068 \n",
      "Minibatch iteration 4/100: mean batch inertia: 6900143.539267, ewa inertia: 6900143.539267 \n",
      "Minibatch iteration 5/100: mean batch inertia: 6215027.407943, ewa inertia: 6215027.407943 \n",
      "Minibatch iteration 6/100: mean batch inertia: 6816015.564868, ewa inertia: 6816015.564868 \n",
      "Minibatch iteration 7/100: mean batch inertia: 6965864.772572, ewa inertia: 6965864.772572 \n",
      "Minibatch iteration 8/100: mean batch inertia: 6678362.976430, ewa inertia: 6678362.976430 \n",
      "Minibatch iteration 9/100: mean batch inertia: 6860507.108726, ewa inertia: 6860507.108726 \n",
      "Minibatch iteration 10/100: mean batch inertia: 5772845.914500, ewa inertia: 5772845.914500 \n",
      "Minibatch iteration 11/100: mean batch inertia: 6879822.327338, ewa inertia: 6879822.327338 \n",
      "Minibatch iteration 12/100: mean batch inertia: 6483119.215511, ewa inertia: 6483119.215511 \n",
      "Minibatch iteration 13/100: mean batch inertia: 5940884.451655, ewa inertia: 5940884.451655 \n",
      "Minibatch iteration 14/100: mean batch inertia: 7001424.230863, ewa inertia: 7001424.230863 \n",
      "Minibatch iteration 15/100: mean batch inertia: 6751704.391886, ewa inertia: 6751704.391886 \n",
      "Minibatch iteration 16/100: mean batch inertia: 6728816.421900, ewa inertia: 6728816.421900 \n",
      "Minibatch iteration 17/100: mean batch inertia: 6465482.678283, ewa inertia: 6465482.678283 \n",
      "Minibatch iteration 18/100: mean batch inertia: 6988291.306297, ewa inertia: 6988291.306297 \n",
      "Minibatch iteration 19/100: mean batch inertia: 6436346.004375, ewa inertia: 6436346.004375 \n",
      "Minibatch iteration 20/100: mean batch inertia: 6281977.089628, ewa inertia: 6281977.089628 \n",
      "Converged (lack of improvement in inertia) at iteration 20/100\n",
      "Computing label assignment and total inertia\n",
      "Computing label assignment and total inertia\n",
      "Computing label assignment and total inertia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Advait\\Anaconda3\\lib\\site-packages\\deepposekit\\annotate\\gui\\Annotator.py:185: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.image_idx = np.sum(np.all(h5file[\"annotated\"].value, axis=1)) - 1\n",
      "C:\\Users\\Advait\\Anaconda3\\lib\\site-packages\\deepposekit\\annotate\\gui\\Annotator.py:199: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  with h5py.File(self.datapath) as h5file:\n",
      "C:\\Users\\Advait\\Anaconda3\\lib\\site-packages\\deepposekit\\annotate\\gui\\Annotator.py:218: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  with h5py.File(self.datapath) as h5file:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "annotate_dataset(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1612973077879,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "blGahhS_rfE_",
    "outputId": "fb9c3cb5-342c-43d1-93f1-704b5124af72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hand.mp4', 'hand_raw.mp4', 'skeleton.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1612973078397,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "oOfG7rEFrbcy",
    "outputId": "61c5b1e9-abe3-4f38-fd10-b6b347c9c004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Work\\\\github repos\\\\deepposekit_data_custom\\\\hand/hand_annotation_set.h5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOME + f'{source}_annotation_set.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1612973078986,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "Qs2jbvr5rAQe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def prepare_model():\n",
    "\n",
    "    print(\"Loading Data Generator\")\n",
    "    data_generator = DataGenerator(HOME + f'{source}_annotation_set.h5', mode=\"annotated\")\n",
    "\n",
    "    print(\"Creating Data Augmenter\")\n",
    "    augmenter = []\n",
    "    augmenter.append(FlipAxis(data_generator, axis=0))  # flip image up-down\n",
    "    augmenter.append(FlipAxis(data_generator, axis=1))  # flip image left-right\n",
    "\n",
    "    sometimes = []\n",
    "    sometimes.append(iaa.Affine(scale={\"x\": (0.95, 1.05), \"y\": (0.95, 1.05)},\n",
    "                                translate_percent={'x': (-0.05, 0.05), 'y': (-0.05, 0.05)},\n",
    "                                shear=(-8, 8),\n",
    "                                order=ia.ALL,\n",
    "                                cval=ia.ALL,\n",
    "                                mode=ia.ALL)\n",
    "                     )\n",
    "    sometimes.append(iaa.Affine(scale=(0.8, 1.2),\n",
    "                                mode=ia.ALL,\n",
    "                                order=ia.ALL,\n",
    "                                cval=ia.ALL)\n",
    "                     )\n",
    "    augmenter.append(iaa.Sometimes(0.75, sometimes))\n",
    "    augmenter.append(iaa.Affine(rotate=(-180, 180),\n",
    "                                mode=ia.ALL,\n",
    "                                order=ia.ALL,\n",
    "                                cval=ia.ALL)\n",
    "                     )\n",
    "    augmenter = iaa.Sequential(augmenter)\n",
    "\n",
    "    print(\"Creating Training Generator\")\n",
    "    train_generator = TrainingGenerator(generator=data_generator,\n",
    "                                        downsample_factor=3,\n",
    "                                        augmenter=augmenter,\n",
    "                                        sigma=3,\n",
    "                                        validation_split=0.3,\n",
    "                                        use_graph=True,\n",
    "                                        random_seed=1,\n",
    "                                        graph_scale=1)\n",
    "    print(train_generator.get_config())\n",
    "    train_generator.on_epoch_end()\n",
    "\n",
    "    with tf.device(\"gpu:0\"):\n",
    "        print(\"[INFO] Preparing Model\")\n",
    "        # SELECT MODEL\n",
    "\n",
    "        # model = StackedDenseNet(train_generator, n_stacks=5, growth_rate=32, pretrained=True)\n",
    "        # model = DeepLabCut(train_generator, backbone=\"resnet50\")\n",
    "        # model = DeepLabCut(train_generator, backbone=\"mobilenetv2\", alpha=0.75) # Increase alpha to improve accuracy\n",
    "        model = DeepLabCut(train_generator, backbone=\"densenet121\")\n",
    "        # model = LEAP(train_generator)\n",
    "        # model = StackedHourglass(train_generator)\n",
    "\n",
    "        model.get_config()\n",
    "        reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, verbose=1, patience=20)\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            HOME + \"best_model_densenet.h5\",\n",
    "            monitor=\"loss\",\n",
    "            # monitor=\"loss\" # use if validation_split=0\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "        )\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor=\"loss\",\n",
    "            # monitor=\"loss\" # use if validation_split=0\n",
    "            min_delta=0.001,\n",
    "            patience=100,\n",
    "            verbose=1\n",
    "    )\n",
    "\n",
    "        print(\"Training model...\")\n",
    "        callbacks = [early_stop, reduce_lr, model_checkpoint]\n",
    "        model.fit(\n",
    "            batch_size=1,\n",
    "            validation_batch_size=5,\n",
    "            callbacks=callbacks,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=None,\n",
    "        )\n",
    "\n",
    "        model = load_model(\n",
    "            HOME + \"best_model_densenet.h5\",\n",
    "            augmenter=augmenter,\n",
    "            generator=data_generator,\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            batch_size=1,\n",
    "            validation_batch_size=5,\n",
    "            callbacks=callbacks,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184366,
     "status": "ok",
     "timestamp": 1612973264799,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "2acH7dpDo6SN",
    "outputId": "5ef93873-a1f2-45d0-8eb9-514e6dce8266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data Generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepposekit/io/DataGenerator.py:81: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.annotated = np.all(h5file[\"annotated\"].value, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Augmenter\n",
      "Creating Training Generator\n",
      "[INFO] Preparing Model\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff39e204c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff39e204c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff39e204c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff39e204c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff34350aa90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff34350aa90>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deepposekit/models/backend/utils.py:35: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepposekit/models/engine.py:145: UserWarning: \n",
      "Automatically compiling with default settings: model.compile('adam', 'mse')\n",
      "Call model.compile() manually to use non-default settings.\n",
      "\n",
      "  \"\"\"\\nAutomatically compiling with default settings: model.compile('adam', 'mse')\\n\"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/deepposekit/models/engine.py:161: UserWarning: No validation set detected, so validation step will not be run and `val_loss` will not be available.\n",
      "  \"No validation set detected, so validation step will not be run and `val_loss` will not be available.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/9 [=========================>....] - ETA: 5s - loss: 11.3334 \n",
      "Epoch 00001: loss improved from inf to 11.15484, saving model to /content/drive/MyDrive/GitHub IU/bam/deepposekit_clone/deepposekit_data_custom/human/best_model_densenet.h5\n",
      "9/9 [==============================] - 54s 6s/step - loss: 11.1548\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff3231700f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff3231700f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff3231700f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff3231700f0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff20bd79320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff20bd79320>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "8/9 [=========================>....] - ETA: 2s - loss: 9.8932\n",
      "Epoch 00001: loss improved from 11.15484 to 9.92928, saving model to /content/drive/MyDrive/GitHub IU/bam/deepposekit_clone/deepposekit_data_custom/human/best_model_densenet.h5\n",
      "9/9 [==============================] - 34s 4s/step - loss: 9.9293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prepare_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1612973443816,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "c81LKvmgrDRe"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_video():\n",
    "    print(\"[INFO] Creating Output Video\")\n",
    "\n",
    "    with tf.device(\"gpu:0\"):\n",
    "        model = load_model(HOME + 'best_model_densenet.h5')\n",
    "\n",
    "    model_size = tuple(model.input_shape[:2])\n",
    "    print(model_size, model_size[::-1])\n",
    "    model_size = model_size[::-1] \n",
    "\n",
    "    print(\"Reading Video...\")\n",
    "    reader = VideoReader(HOME + f'{source}.mp4', batch_size=1, gray=True)\n",
    "    predictions = model.predict(reader, verbose=1)\n",
    "    np.save(HOME + 'predictions.npy', predictions)\n",
    "    #############################################\n",
    "\n",
    "    data_generator = DataGenerator(HOME + f'{source}_annotation_set.h5')\n",
    "    predictions = predictions[..., :2]\n",
    "    print(predictions.shape)\n",
    "\n",
    "    cmap = plt.cm.hsv(np.linspace(0, 1, data_generator.keypoints_shape[0]))[:, :3][:, ::-1] * 255\n",
    "\n",
    "    writer = VideoWriter(HOME + f'{source}_predicted.mp4', model_size, 'mp4v', 30.0, color=True)\n",
    "    for frame, keypoints in tqdm.tqdm(zip(reader, predictions)):\n",
    "        frame = frame[0]\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)\n",
    "        for i, node in enumerate(data_generator.graph):\n",
    "            if node >= 0:\n",
    "                pt1 = keypoints[i]\n",
    "                pt2 = keypoints[node]\n",
    "                cv2.line(frame, (pt1[0], pt1[1]), (pt2[0], pt2[1]), (0, 0, 255), 1, cv2.LINE_AA)\n",
    "        for i, keypoint in enumerate(keypoints):\n",
    "            keypoint = keypoint.astype(int)\n",
    "            cv2.circle(frame, (keypoint[0], keypoint[1]), 1, tuple(cmap[i]), -1, cv2.LINE_AA)\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.close()\n",
    "    reader.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83101,
     "status": "ok",
     "timestamp": 1612973527591,
     "user": {
      "displayName": "Advait Save",
      "photoUrl": "",
      "userId": "08904726702539992993"
     },
     "user_tz": 300
    },
    "id": "g_an9IySo7Z6",
    "outputId": "163c826c-9822-405f-8059-ff95b1998be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Creating Output Video\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff20555e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff20555e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff20555e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method ImageNetPreprocess.call of <deepposekit.models.layers.deeplabcut.ImageNetPreprocess object at 0x7ff20555e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff1fc4276a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method SubpixelMaxima2D.call of <deepposekit.models.layers.subpixel.SubpixelMaxima2D object at 0x7ff1fc4276a0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
      "(320, 640) (640, 320)\n",
      "Reading Video...\n",
      "275/275 [==============================] - 21s 75ms/step\n",
      "(275, 7, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deepposekit/io/DataGenerator.py:81: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  self.annotated = np.all(h5file[\"annotated\"].value, axis=1)\n",
      "275it [00:00, 408.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Process Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_video()\n",
    "print(\"[INFO] Process Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAA015xfswNS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOZj4nVDEFCklwxVu/2JDnn",
   "collapsed_sections": [],
   "mount_file_id": "11JwAmjvNnvqFsJOUsTWG7Q_zCRqJssR6",
   "name": "DeepPoseKit main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
